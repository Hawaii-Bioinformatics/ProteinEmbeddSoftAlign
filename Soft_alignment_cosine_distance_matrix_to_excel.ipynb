{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install biopython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ed6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "from collections import defaultdict \n",
    "from Bio import SeqIO \n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import numpy as np \n",
    "import torch.nn  as nn\n",
    "import torch\n",
    "import networkx as nx\n",
    "from io import StringIO\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac4d53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set directories\n",
    "fasta_directory = './data/example/fasta'\n",
    "fasta_file = 'test.fasta'\n",
    "\n",
    "# The following assumes all embeddings are stored in the same directory. \n",
    "embedding_directory = './data/example/fasta/embeddigs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d134e404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Load FASTA file \n",
    "\"\"\"\n",
    "\n",
    "seqs = SeqIO.to_dict(SeqIO.parse(fasta_directory + fasta_file, 'fasta'))\n",
    "\n",
    "# Create a list of sequence IDs for easy access.\n",
    "seqids_list = list(seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd07432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load torch embeddings of desired sequences to soft align. \n",
    "# Sequence IDs can be stored as either seq_1 or seq_2, results do not change.\n",
    "\n",
    "seq_1 = torch.load(f\"{embedding_directory + seqids_list[0]}.pt\")\n",
    "seq_2 = torch.load(f\"{embedding_directory + seqids_list[1]}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "019d2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input of this function are two dictionaries (seq_1 and seq_2) containing the sequence representations\n",
    "i = 0\n",
    "def get_data_matrix(seq_1, seq_2):\n",
    "    x_tensor = seq_1[\"representations\"][36]\n",
    "    y_tensor = seq_2[\"representations\"][36]\n",
    "\n",
    "    # Normalize the vectors (this is needed for cosine similarity)\n",
    "    x_norm = x_tensor / x_tensor.norm(dim=1)[:, None]\n",
    "    y_norm = y_tensor / y_tensor.norm(dim=1)[:, None]\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_similarity_matrix = torch.mm(x_norm, y_norm.transpose(0,1))\n",
    "\n",
    "    # If you need the output as a DataFrame\n",
    "    data = pd.DataFrame(cosine_similarity_matrix.numpy())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39661834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters to determine mutual matches\n",
    "\n",
    "# Find the top_n cosine distances in each column/row of soft align matrix.\n",
    "top_n = 3\n",
    "\n",
    "# Set hyperparameter for length of diagonals to be considered coincidental.\n",
    "min_diagonal_length = 10\n",
    "\n",
    "# Set hyperparameter for amount of mismatches in a diagonal \n",
    "# that are assumed to be the same based on amino acid context.\n",
    "max_mismatches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74cc9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mutual_matches(data):\n",
    "    \"\"\" \n",
    "    find_mutual_matches takes 'data' dataframe containing cosine \n",
    "    distance matrix of seq_1, seq_2.\n",
    "    \n",
    "    If a cosine distance is a top_n distance in a row \n",
    "    and is also a top_n distance in the column that cell \n",
    "    is considered mutual matches.\n",
    "    \n",
    "    Mutual matches are then stored in 'matches' set.\n",
    "    \"\"\"\n",
    "    # Find the top_n distances in each row.\n",
    "    rows = pd.DataFrame({n: data.T[col].nlargest(top_n).index.tolist() \n",
    "                  for n, col in enumerate(data.T)}).T\n",
    "    \n",
    "    # Find the top_n distances in each column.\n",
    "    cols = pd.DataFrame({n: data[row].nlargest(top_n).index.tolist() \n",
    "                  for n, row in enumerate(data)})\n",
    "    \n",
    "    matches = set()\n",
    "\n",
    "    # Loop over top_n in the rows and columns to find mutual matches.\n",
    "    for i, n_cols in enumerate(rows.values):\n",
    "        for c in n_cols:\n",
    "            if i in cols.iloc[:, c].values:            \n",
    "                matches.add((i, int(c)))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4065027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matching_neighbors(seq_1_str, seq_2_str, matches):\n",
    "    \"\"\"\n",
    "    seq_1_str, seq_2_str are strings containing the sequence to the\n",
    "    corresponding seq_1,seq_2 sequence IDs.\n",
    "    \n",
    "    matches is the set that is passed from the find_mutual_matches\n",
    "    function.\n",
    "    \n",
    "    add_matching_neighbors function considers neighbors to matches\n",
    "    with identical amino acids as matches and adds them to the \n",
    "    'matches' set.\n",
    "    \"\"\" \n",
    "    temp_set = set()\n",
    "\n",
    "    for match in matches:\n",
    "        if match[0] > 0 and match[1] > 0 and (seq_1_str[match[0]-1] ==  seq_2_str[match[1]-1]):\n",
    "            temp_set.add((match[0]-1, match[1]-1))\n",
    "\n",
    "        if match[0] < len(seq_1_str) - 1  and match[1] < len(seq_2_str)-1 and  (seq_1_str[match[0]+1] == seq_2_str[match[1]+1]):\n",
    "            temp_set.add((match[0]+1, match[1]+1))\n",
    "    \n",
    "    matches = matches.union(temp_set)\n",
    "    \n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc7ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exclusive_intervals(intervals):\n",
    "    \"\"\"\n",
    "    intervals = found_matches\n",
    "    found_matches stores matches of identical amino acids when \n",
    "    sequence strings are rotated.\n",
    "    \n",
    "    find_exclusive_intervals returns found_matches that were not \n",
    "    identified in by other match finding functions. \n",
    "    \"\"\"\n",
    "    exclusive_intervals = []\n",
    "\n",
    "    for i in intervals:\n",
    "        is_included = False\n",
    "\n",
    "        for j in intervals:\n",
    "            if i != j and i[0] >= j[0] and i[1] <= j[1]:\n",
    "                is_included = True\n",
    "                break\n",
    "\n",
    "        if not is_included:\n",
    "            exclusive_intervals.append(i)\n",
    "\n",
    "    return exclusive_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c145dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(s, t, offset_val, matches, k, nb_errors=2):\n",
    "    \"\"\"\n",
    "    s = seq_1_str\n",
    "    t = seq_2_str\n",
    "    offset_value = l or r rotation offset value\n",
    "    matches = 'matches' set\n",
    "    k = max_mismatches\n",
    "    \n",
    "    find_matches searches through rotated sequence alignments and if \n",
    "    amino acids in the same positions are identical, they are considered \n",
    "    a match.\n",
    "    \"\"\"\n",
    "\n",
    "    found_matches = []\n",
    "\n",
    "    max_errors_available = nb_errors\n",
    "\n",
    "    i = 0\n",
    "    end = 1\n",
    "    nb_matches = 0\n",
    "    while i < len(s) - k:\n",
    "        start = i\n",
    "        # check if the current character in s matches the current character in t\n",
    "        if s[i] == t[i] or (i, i+offset_val) in matches:\n",
    "            nb_matches+=1\n",
    "            # nested loop to iterate through the rest of the characters in s\n",
    "            for j in range(i + 1, len(s)):\n",
    "                # check if the current character in s matches the current character in t\n",
    "                if s[j] == t[j] or (j, j+offset_val) in matches:\n",
    "                    end = j\n",
    "                    nb_matches += 1\n",
    "                else:\n",
    "                    # decrement the number of errors allowed in the potential match\n",
    "                    max_errors_available -= 1\n",
    "\n",
    "                # check if the number of errors encountered so far is \n",
    "                # greater than the allowed number\n",
    "                if max_errors_available < 0:\n",
    "                    # check if the potential match is at least max_mismatches characters long\n",
    "                    if nb_matches >= k:\n",
    "                        # add the match to the found_matches list\n",
    "                        found_matches.append((start, end))\n",
    "\n",
    "                    # reset the number matches\n",
    "                    nb_matches = 0\n",
    "                    # reset the number of errors allowed in the potential match\n",
    "                    max_errors_available = nb_errors\n",
    "                    # update the outer loop index and potential match start and end indices\n",
    "                    i += 1\n",
    "                    start = i\n",
    "                    end = i + 1\n",
    "                    break\n",
    "            # check if the potential match is at least max_mismatches characters long\n",
    "            if nb_matches >= k:\n",
    "                # add the match to the found_matches list\n",
    "                found_matches.append((start, end))\n",
    "            # update the outer loop index and potential match start and end indices\n",
    "            i += 1\n",
    "            start = i\n",
    "            end = i + 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        # combine matches included in other matches\n",
    "        unique_found_matches = find_exclusive_intervals(found_matches)\n",
    "\n",
    "\n",
    "    return unique_found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e975812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rrotation(s, t, offset):\n",
    "    \"\"\" \n",
    "    generate_lrotation inputs: \n",
    "    s = seq_1_str\n",
    "    t = seq_2_str\n",
    "    offset = position in sequence where offset occurs\n",
    "    \n",
    "    generate_lrotation function rotates seq_2_str 1 position right\n",
    "    along corresponding seq_1_str for each iteration and \n",
    "    returns rotated string. \n",
    "    \"\"\"\n",
    "    # If the offset is larger than the length of the \n",
    "    # sequence 't', raise an exception.\n",
    "    if offset >= len(s):\n",
    "        raise Exception(f\"offset {offset} larger than seq length {len(s)}\")\n",
    "    \n",
    "    lgaps = '-' * offset\n",
    "    \n",
    "    # Extract a substring from sequence 't' starting from the offset \n",
    "    # index up to the length of 's'. \n",
    "    # my_str represents the part of 't' that will be kept after the rotation.\n",
    "    my_str = t[0:len(s)-offset]\n",
    "    \n",
    "    # Generate a string of '-' characters of length equal to the remaining \n",
    "    # length of 's' after adding 'my_str'.\n",
    "    # rgaps represents the right gaps that will be added to the end of the sequence.\n",
    "    rgaps = '-' * (len(s) - len(lgaps  + my_str))\n",
    "    \n",
    "    return lgaps  + my_str + rgaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65c7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lrotation(s, t, offset):\n",
    "    \"\"\"\n",
    "    generate_lrotation inputs: \n",
    "    s = seq_1_str\n",
    "    t = seq_2_str\n",
    "    offset = position in sequence where offset occurs\n",
    "    \n",
    "    generate_lrotation function rotates seq_2_str 1 position left\n",
    "    along corresponding seq_1_str for each iteration and \n",
    "    returns rotated string. \n",
    "    \"\"\"\n",
    "    # If the offset is larger than the length of the \n",
    "    # sequence 't', raise an exception.\n",
    "    if offset >= len(t):\n",
    "        raise Exception(f\"offset {offset} larger than seq length {len(s)}\")\n",
    "    \n",
    "    # Extract a substring from sequence 't' starting from the offset \n",
    "    # index up to the length of 's'. \n",
    "    # my_str represents the part of 't' that will be kept after the rotation.\n",
    "    my_str = t[offset:len(s)]\n",
    "    \n",
    "    # Generate a string of '-' characters of length equal to the remaining \n",
    "    # length of 's' after adding 'my_str'.\n",
    "    # rgaps represents the right gaps that will be added to the end of the sequence.\n",
    "    rgaps = '-' * (len(s) - len(my_str))\n",
    "    \n",
    "    return my_str + rgaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed0ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_matches(s, t, k, matched_pairs):\n",
    "    \"\"\"\n",
    "    find_all_matches inputs:\n",
    "    s = seq_1 sequence string denoted as 'seq_1_str'\n",
    "    t = seq_2 sequence string denoted as 'seq_2_str'\n",
    "    k = max_mismatches, hyperparameter defined above for amount of \n",
    "    mismatches allowed.\n",
    "    matched_pairs = current 'matches' list, which contains mutual matches \n",
    "    and matching neighbors. \n",
    "    \"\"\"\n",
    "    all_matches = []\n",
    "\n",
    "    # In each iteration, generate a right rotation of 'seq_2_str' by the \n",
    "    # current index and run find_match function to identify matching pairs \n",
    "    # in 'seq_1_str' and 'seq_2_str' after rotation.\n",
    "    # Matched pairs identified during rotation are added to all_matches\n",
    "    # list. \n",
    "    for i in range(0, len(s)):\n",
    "        t_offset =  generate_rrotation(s, t, i)\n",
    "        \n",
    "        match_in_i = find_matches(s, t_offset, -i, matched_pairs, k)\n",
    "        \n",
    "        # Adds another match along the same diagonal to match_in_i\n",
    "        match_in_j =  [(x-i, y-i) for x, y in match_in_i]\n",
    "        \n",
    "        # Adds both matches along same diagonal to 'all_matches' list\n",
    "        all_matches.extend(list(zip(match_in_i, match_in_j)))\n",
    "\n",
    "    # In each iteration, generate a left rotation of 'seq_2_str' by the \n",
    "    # current index and run find_match function to identify matching pairs \n",
    "    # in 'seq_1_str' and 'seq_2_str' after rotation.\n",
    "    # Matched pairs identified during rotation are added to all_matches\n",
    "    # list. \n",
    "    for i in range(1, len(t)):\n",
    "        t_offset =  generate_lrotation(s, t, i)\n",
    "        \n",
    "        match_in_i = find_matches(s, t_offset, +i, matched_pairs, k)\n",
    "        \n",
    "        # Adds another match along the same diagonal to match_in_i\n",
    "        match_in_j =  [(x+i, y+i) for x, y in match_in_i]\n",
    "        \n",
    "        # Adds both matches along same diagonal to 'all_matches' list\n",
    "        all_matches.extend(list(zip(match_in_i, match_in_j)))\n",
    "        \n",
    "    return all_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe3d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paths_graph(matches):\n",
    "    \"\"\"\n",
    "    matches = matches \n",
    "    \n",
    "    build_paths_graph function finds longest diagonals from sorted matches.\n",
    "    \"\"\"\n",
    "    dag = {}\n",
    "    \n",
    "    graph = nx.DiGraph()\n",
    "    \n",
    "    # Determine the maximum depth of the matches, \n",
    "    # which is the highest index in the first element of the match pairs.\n",
    "    max_depth = max([x[0] for x in matches])\n",
    "    \n",
    "    # Sort the matches based on the second element of the match pairs.\n",
    "    sorted_matches = sorted(matches, key=lambda x: x[1])\n",
    "    \n",
    "    # Loop over the sorted matches and \n",
    "    # add edges between them to build the graph.\n",
    "    for i in range(len(sorted_matches) - 1):\n",
    "        last_depth =  max_depth\n",
    "        dag[sorted_matches[i]] = []\n",
    "\n",
    "        for j in range(i+1, len(sorted_matches)):\n",
    "            \n",
    "            if (sorted_matches[i][0] == sorted_matches[j][0]) or (sorted_matches[i][1] == sorted_matches[j][1]):\n",
    "                # Don't consider overlapping cells\n",
    "                continue\n",
    "\n",
    "            if (sorted_matches[j][0]) < last_depth and  (sorted_matches[j][0] >  sorted_matches[i][0]):\n",
    "                dag[sorted_matches[i]].append(sorted_matches[j])\n",
    "                seq_1_idx, seq_2_idx = sorted_matches[j]\n",
    "                graph.add_edge(sorted_matches[i], sorted_matches[j], weigth=data.iloc[seq_1_idx, seq_2_idx])\n",
    "                last_depth = sorted_matches[j][0]\n",
    "                \n",
    "    return graph\n",
    "\n",
    "\n",
    "def get_valid_diagonals(valid_segments):\n",
    "    \"\"\"\n",
    "    valid_segments = sorted(valid_segments)\n",
    "    \n",
    "    get_valid_diagonals function identifies matches that occur consecutively\n",
    "    in a diagonal and stores them in a dictionary 'valid_diagonals'. \n",
    "    \"\"\"\n",
    "    valid_diagonals = defaultdict(int)\n",
    "    \n",
    "    # Loop over the valid segments and add the length of each segment \n",
    "    # to its corresponding diagonal in the dictionary.\n",
    "    for x in  valid_segments:\n",
    "        min_val = min(x[0][0], x[1][0])\n",
    "        diag = (x[0][0] - min_val, x[1][0]-min_val)\n",
    "        valid_diagonals[diag] += x[0][1] - x[0][0] + 1\n",
    "    \n",
    "    return valid_diagonals\n",
    "\n",
    "\n",
    "def cleanup_matches(matches, valid_diagonals):\n",
    "    \"\"\"\n",
    "    matches = matches (all matches found)\n",
    "    valid_diagonals = valid_diagonals\n",
    "    \n",
    "    cleanup_matches removes matches that do not occur in a valid_diagonal\n",
    "    but are shorter than min_diagonal_length (hyperparameter).\n",
    "    \"\"\"\n",
    "    remove_elems  = []\n",
    "    \n",
    "    # Loop over the matches and add any invalid match to the removal list\n",
    "    for x in matches:\n",
    "        min_val = min(x[0], x[1])\n",
    "        diag = (x[0] - min_val, x[1]-min_val)\n",
    "        if valid_diagonals[diag] < min_diagonal_length:\n",
    "            remove_elems.append(x)\n",
    "    \n",
    "    # Remove the invalid matches from the original list\n",
    "    matches = list(set(matches).difference(remove_elems))\n",
    "    \n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb192dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new excel file. \n",
    "# Excel (the program should already be open) \n",
    "wb = xw.Book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fcce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Sheet 0 \n",
    "sheet = wb.sheets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aee8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add first seq with indices at cols 0 and 1\n",
    "sheet['A3'].value = [[x] for x in range(0,len(seqs[seqids_list[0]].seq))]\n",
    "sheet['B3'].value = [[x] for x in seqs[seqids_list[0]].seq]\n",
    "\n",
    "### Add second seq with indices at rows 0 and 1\n",
    "sheet['C1'].value = list(range(0, len(seqs[seqids_list[1]].seq)))\n",
    "sheet['C2'].value = list(seqs[seqids_list[1]].seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "955c9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate cosine distance matrix\n",
    "data = get_data_matrix(seq_1,seq_2)\n",
    "\n",
    "### Print cosine distance matrix starting at position C3\n",
    "sheet['C3'].options(index=False).value = data.to_numpy()\n",
    "\n",
    "# Save sequence 1 and 2 as strings\n",
    "seq_1_str =  str(seqs[seqids_list[0]].seq)\n",
    "seq_2_str =  str(seqs[seqids_list[1]].seq)\n",
    "\n",
    "# Find mutual matches in the data matrix\n",
    "matches = find_mutual_matches(data)\n",
    "# Add matching neighbors to the set of matches\n",
    "matches = add_matching_neighbors(seq_1_str, seq_2_str, matches)\n",
    "\n",
    "# Find all valid segments in the matches\n",
    "valid_segments = find_all_matches(seq_1_str, seq_2_str, max_mismatches, matches)\n",
    "# Sort the valid segments based on the first element of each segment\n",
    "valid_segments = sorted(valid_segments, key=lambda x: x[0][0])\n",
    "\n",
    "# Get the valid diagonals from the valid segments\n",
    "valid_diagonals = get_valid_diagonals(valid_segments)\n",
    "\n",
    "# Clean up the matches by removing any invalid matches\n",
    "matches = cleanup_matches(matches, valid_diagonals)\n",
    "\n",
    "longest_path = []\n",
    "\n",
    "# If there are any matches left, build a paths graph and find the longest path in the graph\n",
    "if len(matches) > 0:            \n",
    "    graph = build_paths_graph(matches)\n",
    "    longest_path = nx.dag_longest_path(graph)\n",
    "    \n",
    "# Color cells in longest_path list yellow\n",
    "for m in longest_path:\n",
    "    m = (m[0]+2, m[1]+2)\n",
    "    sheet[m].color = (254, 254, 69)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
